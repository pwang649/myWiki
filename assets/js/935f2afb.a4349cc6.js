"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[53],{1109:i=>{i.exports=JSON.parse('{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"link","label":"Intro","href":"/myWiki/docs/Intro","docId":"Intro"},{"type":"category","label":"Parallel Computation","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"RL DP Code","href":"/myWiki/docs/Code/Code - DP","docId":"Code/Code - DP"},{"type":"link","label":"Gradient Descent Code","href":"/myWiki/docs/Code/Code - GD","docId":"Code/Code - GD"},{"type":"link","label":"Linear Programming Code","href":"/myWiki/docs/Code/Code - LP","docId":"Code/Code - LP"},{"type":"link","label":"2048 Verilog","href":"/myWiki/docs/Code/Code - 2048","docId":"Code/Code - 2048"},{"type":"category","label":"Parallel_Computation","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Lab 1","href":"/myWiki/docs/Code/Parallel_Computation/Code - Parallel_Computation - Lab 1","docId":"Code/Parallel_Computation/Code - Parallel_Computation - Lab 1"}]}]},{"type":"category","label":"Robotics","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Introduction","href":"/myWiki/docs/Robotics/Robotics - Intro","docId":"Robotics/Robotics - Intro"},{"type":"link","label":"Start from Scratch","href":"/myWiki/docs/Robotics/Robotics - Scratch","docId":"Robotics/Robotics - Scratch"},{"type":"link","label":"Kinematics","href":"/myWiki/docs/Robotics/Robotics - Kinematics","docId":"Robotics/Robotics - Kinematics"}]},{"type":"category","label":"Machine Learning Theory","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Gentle Start","href":"/myWiki/docs/Machine Learning Theory/Machine Learning Theory - Start","docId":"Machine Learning Theory/Machine Learning Theory - Start"},{"type":"link","label":"Empirical Risk Minimization","href":"/myWiki/docs/Machine Learning Theory/Machine Learning Theory - ERM","docId":"Machine Learning Theory/Machine Learning Theory - ERM"},{"type":"link","label":"PAC Learning","href":"/myWiki/docs/Machine Learning Theory/Machine Learning Theory - PAC","docId":"Machine Learning Theory/Machine Learning Theory - PAC"},{"type":"link","label":"Bias-Complexity Trade-off","href":"/myWiki/docs/Machine Learning Theory/Machine Learning Theory - Bias-Complexity","docId":"Machine Learning Theory/Machine Learning Theory - Bias-Complexity"},{"type":"link","label":"VC-Dimension","href":"/myWiki/docs/Machine Learning Theory/Machine Learning Theory - VC","docId":"Machine Learning Theory/Machine Learning Theory - VC"},{"type":"link","label":"Conclusion","href":"/myWiki/docs/Machine Learning Theory/Machine Learning Theory - Conclusion","docId":"Machine Learning Theory/Machine Learning Theory - Conclusion"}]},{"type":"category","label":"Machine Learning Algorithms","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Gentle Start","href":"/myWiki/docs/Machine Learning Algorithms/Machine Learning Algorithms - Start","docId":"Machine Learning Algorithms/Machine Learning Algorithms - Start"},{"type":"link","label":"Linear Predictors","href":"/myWiki/docs/Machine Learning Algorithms/Machine Learning Algorithms - Linear Predictors","docId":"Machine Learning Algorithms/Machine Learning Algorithms - Linear Predictors"},{"type":"link","label":"Boosting","href":"/myWiki/docs/Machine Learning Algorithms/Machine Learning Algorithms - Boosting","docId":"Machine Learning Algorithms/Machine Learning Algorithms - Boosting"},{"type":"link","label":"Neural Networks","href":"/myWiki/docs/Machine Learning Algorithms/Machine Learning Algorithms - Neural Networks","docId":"Machine Learning Algorithms/Machine Learning Algorithms - Neural Networks"}]},{"type":"category","label":"Reinforcement Learning","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Overview","href":"/myWiki/docs/Reinforcement Learning/Reinforcement Learning - Overview","docId":"Reinforcement Learning/Reinforcement Learning - Overview"},{"type":"link","label":"Multi-armed Bandits","href":"/myWiki/docs/Reinforcement Learning/Reinforcement Learning - Bandit","docId":"Reinforcement Learning/Reinforcement Learning - Bandit"},{"type":"link","label":"Markov Decision Process","href":"/myWiki/docs/Reinforcement Learning/Reinforcement Learning - MDP","docId":"Reinforcement Learning/Reinforcement Learning - MDP"},{"type":"link","label":"Dyanamic Programming","href":"/myWiki/docs/Reinforcement Learning/Reinforcement Learning - DP","docId":"Reinforcement Learning/Reinforcement Learning - DP"},{"type":"link","label":"Monte Carlo Methods","href":"/myWiki/docs/Reinforcement Learning/Reinforcement Learning - MC","docId":"Reinforcement Learning/Reinforcement Learning - MC"},{"type":"link","label":"Temporal-Difference Learning","href":"/myWiki/docs/Reinforcement Learning/Reinforcement Learning - TD","docId":"Reinforcement Learning/Reinforcement Learning - TD"},{"type":"link","label":"n-step Bootstrapping","href":"/myWiki/docs/Reinforcement Learning/Reinforcement Learning - n-step","docId":"Reinforcement Learning/Reinforcement Learning - n-step"},{"type":"link","label":"Concurrent Q-Learning","href":"/myWiki/docs/Reinforcement Learning/Reinforcement Learning - Concurrent-QL","docId":"Reinforcement Learning/Reinforcement Learning - Concurrent-QL"},{"type":"link","label":"Proximal Policy Optimization Algorithms","href":"/myWiki/docs/Reinforcement Learning/Reinforcement Learning - PPO","docId":"Reinforcement Learning/Reinforcement Learning - PPO"}]},{"type":"category","label":"Optimization","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Basics","href":"/myWiki/docs/Optimization/Optimization - Basics","docId":"Optimization/Optimization - Basics"},{"type":"link","label":"1D Search Methods","href":"/myWiki/docs/Optimization/Optimization - 1D-Search","docId":"Optimization/Optimization - 1D-Search"},{"type":"link","label":"Gradient Descent","href":"/myWiki/docs/Optimization/Optimization - GD","docId":"Optimization/Optimization - GD"},{"type":"link","label":"Conjugate Direction Methods","href":"/myWiki/docs/Optimization/Optimization - Conjugate-GD","docId":"Optimization/Optimization - Conjugate-GD"},{"type":"link","label":"Newton\'s Method","href":"/myWiki/docs/Optimization/Optimization - Newton","docId":"Optimization/Optimization - Newton"},{"type":"link","label":"Linear Programming","href":"/myWiki/docs/Optimization/Optimization - LP","docId":"Optimization/Optimization - LP"},{"type":"link","label":"The Simplex Algorithm","href":"/myWiki/docs/Optimization/Optimization - Simplex","docId":"Optimization/Optimization - Simplex"},{"type":"link","label":"Duality","href":"/myWiki/docs/Optimization/Optimization - Duality","docId":"Optimization/Optimization - Duality"},{"type":"link","label":"Nonlinear Constrained Optimization - Equality","href":"/myWiki/docs/Optimization/Optimization - Constrained_Op_Equality","docId":"Optimization/Optimization - Constrained_Op_Equality"},{"type":"link","label":"KKT","href":"/myWiki/docs/Optimization/Optimization - KKT","docId":"Optimization/Optimization - KKT"},{"type":"link","label":"Lagrangian Duality","href":"/myWiki/docs/Optimization/Optimization - Lagrangian Duality","docId":"Optimization/Optimization - Lagrangian Duality"},{"type":"link","label":"Convex Optimization","href":"/myWiki/docs/Optimization/Optimization - Convex","docId":"Optimization/Optimization - Convex"}]},{"type":"category","label":"Research","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Placement Optmization","href":"/myWiki/docs/Research/Research - Placement Optimization","docId":"Research/Research - Placement Optimization"}]},{"type":"category","label":"Communication Protocols","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Serial Communication","href":"/myWiki/docs/Communication Protocols/Communication Protocols - Serial","docId":"Communication Protocols/Communication Protocols - Serial"},{"type":"link","label":"I2C","href":"/myWiki/docs/Communication Protocols/Communication Protocols - I2C","docId":"Communication Protocols/Communication Protocols - I2C"},{"type":"link","label":"SPI","href":"/myWiki/docs/Communication Protocols/Communication Protocols - SPI","docId":"Communication Protocols/Communication Protocols - SPI"}]},{"type":"link","label":"Handwritten Notes","href":"/myWiki/docs/Handwritten Notes","docId":"Handwritten Notes"}]},"docs":{"Code/Code - 2048":{"id":"Code/Code - 2048","title":"2048 Verilog","description":"Abstract","sidebar":"tutorialSidebar"},"Code/Code - DP":{"id":"Code/Code - DP","title":"RL DP Code","description":"Source","sidebar":"tutorialSidebar"},"Code/Code - GD":{"id":"Code/Code - GD","title":"Gradient Descent Code","description":"All the code is written in matlab. Please visits here for a complete version of my code. The neural network code base is in reference to Dr. Chunming Wang\'s MATH467 project code.","sidebar":"tutorialSidebar"},"Code/Code - LP":{"id":"Code/Code - LP","title":"Linear Programming Code","description":"All the code is written in matlab. Please visits here for a complete version of my code. The code base is in reference to Dr. Chunming Wang\'s MATH467 project code.","sidebar":"tutorialSidebar"},"Code/Parallel_Computation/Code - Parallel_Computation - Lab 1":{"id":"Code/Parallel_Computation/Code - Parallel_Computation - Lab 1","title":"Lab 1","description":"Problem 1","sidebar":"tutorialSidebar"},"Communication Protocols/Communication Protocols - I2C":{"id":"Communication Protocols/Communication Protocols - I2C","title":"I2C","description":"I2C stands for Inter-Integrated Circuit. It is a bus interface connection protocol incorporated into devices for serial communication. It was originally designed by Philips Semiconductor in 1982. Recently, it is a widely used protocol for short-distance communication. It is also known as Two Wired Interface(TWI).","sidebar":"tutorialSidebar"},"Communication Protocols/Communication Protocols - Serial":{"id":"Communication Protocols/Communication Protocols - Serial","title":"Serial Communication","description":"UART vs USART","sidebar":"tutorialSidebar"},"Communication Protocols/Communication Protocols - SPI":{"id":"Communication Protocols/Communication Protocols - SPI","title":"SPI","description":"Serial Peripheral Interface or SPI is a synchronous serial communication protocol that provides full \u2013 duplex communication at very high speeds. Serial Peripheral Interface (SPI) is a master \u2013 slave type protocol that provides a simple and low cost interface between a microcontroller and its peripherals.","sidebar":"tutorialSidebar"},"Handwritten Notes":{"id":"Handwritten Notes","title":"Handwritten Notes","description":"This page contains all the handwritten notes that I\'ve taken while reading research papers and taking classes. They are not necessarily comprehensive.","sidebar":"tutorialSidebar"},"Intro":{"id":"Intro","title":"Intro","description":"Intro","sidebar":"tutorialSidebar"},"Machine Learning Algorithms/Machine Learning Algorithms - Boosting":{"id":"Machine Learning Algorithms/Machine Learning Algorithms - Boosting","title":"Boosting","description":"- The boosting paradigm allows the learner to have smooth control over this tradeoff. The learning starts with a basic class (that might have a large approximation error), and as it progresses the class that the predictor may belong to grows richer.","sidebar":"tutorialSidebar"},"Machine Learning Algorithms/Machine Learning Algorithms - Linear Predictors":{"id":"Machine Learning Algorithms/Machine Learning Algorithms - Linear Predictors","title":"Linear Predictors","description":"First, we define the class of affine functions as","sidebar":"tutorialSidebar"},"Machine Learning Algorithms/Machine Learning Algorithms - Neural Networks":{"id":"Machine Learning Algorithms/Machine Learning Algorithms - Neural Networks","title":"Neural Networks","description":"Feedforward Neural Networks","sidebar":"tutorialSidebar"},"Machine Learning Algorithms/Machine Learning Algorithms - Start":{"id":"Machine Learning Algorithms/Machine Learning Algorithms - Start","title":"Gentle Start","description":"Comming soon","sidebar":"tutorialSidebar"},"Machine Learning Theory/Machine Learning Theory - Bias-Complexity":{"id":"Machine Learning Theory/Machine Learning Theory - Bias-Complexity","title":"Bias-Complexity Trade-off","description":"Error Decomposition","sidebar":"tutorialSidebar"},"Machine Learning Theory/Machine Learning Theory - Conclusion":{"id":"Machine Learning Theory/Machine Learning Theory - Conclusion","title":"Conclusion","description":"The Fundamental Theorem of Statistical Learning","sidebar":"tutorialSidebar"},"Machine Learning Theory/Machine Learning Theory - ERM":{"id":"Machine Learning Theory/Machine Learning Theory - ERM","title":"Empirical Risk Minimization","description":"Principle","sidebar":"tutorialSidebar"},"Machine Learning Theory/Machine Learning Theory - PAC":{"id":"Machine Learning Theory/Machine Learning Theory - PAC","title":"PAC Learning","description":"Definition (PAC-learnability)","sidebar":"tutorialSidebar"},"Machine Learning Theory/Machine Learning Theory - Start":{"id":"Machine Learning Theory/Machine Learning Theory - Start","title":"Gentle Start","description":"Book","sidebar":"tutorialSidebar"},"Machine Learning Theory/Machine Learning Theory - VC":{"id":"Machine Learning Theory/Machine Learning Theory - VC","title":"VC-Dimension","description":"Definition (Shattering)","sidebar":"tutorialSidebar"},"Optimization/Optimization - 1D-Search":{"id":"Optimization/Optimization - 1D-Search","title":"1D Search Methods","description":"- In this section, we are interested in the problem of minimizing an objective function $f:\\\\mathbb\\\\to\\\\mathbb{R}$ (i.e., a one-dimensionla problem). The approach is to use an iterative search algorithm, also called a line-search method.","sidebar":"tutorialSidebar"},"Optimization/Optimization - Basics":{"id":"Optimization/Optimization - Basics","title":"Basics","description":"Book","sidebar":"tutorialSidebar"},"Optimization/Optimization - Conjugate-GD":{"id":"Optimization/Optimization - Conjugate-GD","title":"Conjugate Direction Methods","description":"Code","sidebar":"tutorialSidebar"},"Optimization/Optimization - Constrained_Op_Equality":{"id":"Optimization/Optimization - Constrained_Op_Equality","title":"Nonlinear Constrained Optimization - Equality","description":"Problems with Equality Constraints","sidebar":"tutorialSidebar"},"Optimization/Optimization - Convex":{"id":"Optimization/Optimization - Convex","title":"Convex Optimization","description":"Convex Functions","sidebar":"tutorialSidebar"},"Optimization/Optimization - Duality":{"id":"Optimization/Optimization - Duality","title":"Duality","description":"Suppose that we are given a linear programming problem of the form","sidebar":"tutorialSidebar"},"Optimization/Optimization - GD":{"id":"Optimization/Optimization - GD","title":"Gradient Descent","description":"Code","sidebar":"tutorialSidebar"},"Optimization/Optimization - KKT":{"id":"Optimization/Optimization - KKT","title":"KKT","description":"Karush-Kuhn-Tucker Condition","sidebar":"tutorialSidebar"},"Optimization/Optimization - Lagrangian Duality":{"id":"Optimization/Optimization - Lagrangian Duality","title":"Lagrangian Duality","description":"The Lagrangian","sidebar":"tutorialSidebar"},"Optimization/Optimization - LP":{"id":"Optimization/Optimization - LP","title":"Linear Programming","description":"Formally, a linear program is an optimization problem of the form","sidebar":"tutorialSidebar"},"Optimization/Optimization - Newton":{"id":"Optimization/Optimization - Newton","title":"Newton\'s Method","description":"Multi-Dimensional Newton\'s Method","sidebar":"tutorialSidebar"},"Optimization/Optimization - Simplex":{"id":"Optimization/Optimization - Simplex","title":"The Simplex Algorithm","description":"Understanding the Simplex Method","sidebar":"tutorialSidebar"},"Reinforcement Learning/Reinforcement Learning - Bandit":{"id":"Reinforcement Learning/Reinforcement Learning - Bandit","title":"Multi-armed Bandits","description":"A k-armed Bandit Problem","sidebar":"tutorialSidebar"},"Reinforcement Learning/Reinforcement Learning - Concurrent-QL":{"id":"Reinforcement Learning/Reinforcement Learning - Concurrent-QL","title":"Concurrent Q-Learning","description":"Concurrent Q-learning Algorithm","sidebar":"tutorialSidebar"},"Reinforcement Learning/Reinforcement Learning - DP":{"id":"Reinforcement Learning/Reinforcement Learning - DP","title":"Dyanamic Programming","description":"Dynamic Programming (DP) refers to the collection of algorithms that can be used to compute optimal policies given a perfect model of the environment as an MDP. DP can rarely be used in practice because of their great cost, but are nonetheless important theoretically as all other approaches to computing the value function are, in effect, approximations of DP. DP algorithms are obtained by turning the Bellman equations into assignments, that is, into update rules for improving approximations of the desired value functions.","sidebar":"tutorialSidebar"},"Reinforcement Learning/Reinforcement Learning - MC":{"id":"Reinforcement Learning/Reinforcement Learning - MC","title":"Monte Carlo Methods","description":"What\'s Monte Carlo?","sidebar":"tutorialSidebar"},"Reinforcement Learning/Reinforcement Learning - MDP":{"id":"Reinforcement Learning/Reinforcement Learning - MDP","title":"Markov Decision Process","description":"The Agent\u2013Environment Interface","sidebar":"tutorialSidebar"},"Reinforcement Learning/Reinforcement Learning - n-step":{"id":"Reinforcement Learning/Reinforcement Learning - n-step","title":"n-step Bootstrapping","description":"n-step TD Prediction","sidebar":"tutorialSidebar"},"Reinforcement Learning/Reinforcement Learning - Overview":{"id":"Reinforcement Learning/Reinforcement Learning - Overview","title":"Overview","description":"Book","sidebar":"tutorialSidebar"},"Reinforcement Learning/Reinforcement Learning - PPO":{"id":"Reinforcement Learning/Reinforcement Learning - PPO","title":"Proximal Policy Optimization Algorithms","description":"Intro","sidebar":"tutorialSidebar"},"Reinforcement Learning/Reinforcement Learning - TD":{"id":"Reinforcement Learning/Reinforcement Learning - TD","title":"Temporal-Difference Learning","description":"TD learning is a combination of Monte Carlo ideas and dynamic programming (DP) ideas. Like Monte Carlo methods, TD methods can learn directly from raw experience without a model of the environment\u2019s dynamics. Like DP, TD methods update estimates based in part on other learned estimates, without waiting for a final outcome (they bootstrap).","sidebar":"tutorialSidebar"},"Research/Research - Placement Optimization":{"id":"Research/Research - Placement Optimization","title":"Placement Optmization","description":"Introduction","sidebar":"tutorialSidebar"},"Robotics/Robotics - Intro":{"id":"Robotics/Robotics - Intro","title":"Introduction","description":"I am very excited to start this section, my favorite one, of my wiki. I will try to make this section comprehensive and elaborative, spanning various hot robotics topics such as motion planning, control, and learning. Stay tuned, as I continuously trudge through the bitter and sweet journey of robotics.","sidebar":"tutorialSidebar"},"Robotics/Robotics - Kinematics":{"id":"Robotics/Robotics - Kinematics","title":"Kinematics","description":"Rigid Body","sidebar":"tutorialSidebar"},"Robotics/Robotics - Scratch":{"id":"Robotics/Robotics - Scratch","title":"Start from Scratch","description":"The term robotics was then introduced by Asimov as the science devoted to the study of robots which was based on the three fundamental laws:","sidebar":"tutorialSidebar"}}}')}}]);