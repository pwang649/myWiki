"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[6919],{3905:(e,n,r)=>{r.d(n,{Zo:()=>l,kt:()=>f});var t=r(7294);function i(e,n,r){return n in e?Object.defineProperty(e,n,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[n]=r,e}function o(e,n){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);n&&(t=t.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),r.push.apply(r,t)}return r}function a(e){for(var n=1;n<arguments.length;n++){var r=null!=arguments[n]?arguments[n]:{};n%2?o(Object(r),!0).forEach((function(n){i(e,n,r[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):o(Object(r)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(r,n))}))}return e}function c(e,n){if(null==e)return{};var r,t,i=function(e,n){if(null==e)return{};var r,t,i={},o=Object.keys(e);for(t=0;t<o.length;t++)r=o[t],n.indexOf(r)>=0||(i[r]=e[r]);return i}(e,n);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(t=0;t<o.length;t++)r=o[t],n.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(i[r]=e[r])}return i}var s=t.createContext({}),m=function(e){var n=t.useContext(s),r=n;return e&&(r="function"==typeof e?e(n):a(a({},n),e)),r},l=function(e){var n=m(e.components);return t.createElement(s.Provider,{value:n},e.children)},u={inlineCode:"code",wrapper:function(e){var n=e.children;return t.createElement(t.Fragment,{},n)}},p=t.forwardRef((function(e,n){var r=e.components,i=e.mdxType,o=e.originalType,s=e.parentName,l=c(e,["components","mdxType","originalType","parentName"]),p=m(r),f=i,d=p["".concat(s,".").concat(f)]||p[f]||u[f]||o;return r?t.createElement(d,a(a({ref:n},l),{},{components:r})):t.createElement(d,a({ref:n},l))}));function f(e,n){var r=arguments,i=n&&n.mdxType;if("string"==typeof e||i){var o=r.length,a=new Array(o);a[0]=p;var c={};for(var s in n)hasOwnProperty.call(n,s)&&(c[s]=n[s]);c.originalType=e,c.mdxType="string"==typeof e?e:i,a[1]=c;for(var m=2;m<o;m++)a[m]=r[m];return t.createElement.apply(null,a)}return t.createElement.apply(null,r)}p.displayName="MDXCreateElement"},328:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>s,contentTitle:()=>a,default:()=>u,frontMatter:()=>o,metadata:()=>c,toc:()=>m});var t=r(7462),i=(r(7294),r(3905));const o={id:"Reinforement Learning -",title:"Multi-armed Bandits",sidebar_position:2},a=void 0,c={unversionedId:"Reinforcement Learning/Reinforement Learning -",id:"Reinforcement Learning/Reinforement Learning -",title:"Multi-armed Bandits",description:"Comming soon",source:"@site/docs/Reinforcement Learning/Bandit.md",sourceDirName:"Reinforcement Learning",slug:"/Reinforcement Learning/Reinforement Learning -",permalink:"/myWiki/docs/Reinforcement Learning/Reinforement Learning -",editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/Reinforcement Learning/Bandit.md",tags:[],version:"current",sidebarPosition:2,frontMatter:{id:"Reinforement Learning -",title:"Multi-armed Bandits",sidebar_position:2},sidebar:"tutorialSidebar",previous:{title:"Overview",permalink:"/myWiki/docs/Reinforcement Learning/Reinforement Learning - Overview"},next:{title:"Markov Decision Process",permalink:"/myWiki/docs/Reinforcement Learning/Reinforement Learning - MDP"}},s={},m=[{value:"Comming soon",id:"comming-soon",level:3}],l={toc:m};function u(e){let{components:n,...r}=e;return(0,i.kt)("wrapper",(0,t.Z)({},l,r,{components:n,mdxType:"MDXLayout"}),(0,i.kt)("h3",{id:"comming-soon"},"Comming soon"))}u.isMDXComponent=!0}}]);