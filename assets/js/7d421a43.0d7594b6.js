"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[1879],{3905:(a,e,t)=>{t.d(e,{Zo:()=>N,kt:()=>k});var n=t(7294);function s(a,e,t){return e in a?Object.defineProperty(a,e,{value:t,enumerable:!0,configurable:!0,writable:!0}):a[e]=t,a}function m(a,e){var t=Object.keys(a);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(a);e&&(n=n.filter((function(e){return Object.getOwnPropertyDescriptor(a,e).enumerable}))),t.push.apply(t,n)}return t}function r(a){for(var e=1;e<arguments.length;e++){var t=null!=arguments[e]?arguments[e]:{};e%2?m(Object(t),!0).forEach((function(e){s(a,e,t[e])})):Object.getOwnPropertyDescriptors?Object.defineProperties(a,Object.getOwnPropertyDescriptors(t)):m(Object(t)).forEach((function(e){Object.defineProperty(a,e,Object.getOwnPropertyDescriptor(t,e))}))}return a}function p(a,e){if(null==a)return{};var t,n,s=function(a,e){if(null==a)return{};var t,n,s={},m=Object.keys(a);for(n=0;n<m.length;n++)t=m[n],e.indexOf(t)>=0||(s[t]=a[t]);return s}(a,e);if(Object.getOwnPropertySymbols){var m=Object.getOwnPropertySymbols(a);for(n=0;n<m.length;n++)t=m[n],e.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(a,t)&&(s[t]=a[t])}return s}var i=n.createContext({}),l=function(a){var e=n.useContext(i),t=e;return a&&(t="function"==typeof a?a(e):r(r({},e),a)),t},N=function(a){var e=l(a.components);return n.createElement(i.Provider,{value:e},a.children)},o={inlineCode:"code",wrapper:function(a){var e=a.children;return n.createElement(n.Fragment,{},e)}},c=n.forwardRef((function(a,e){var t=a.components,s=a.mdxType,m=a.originalType,i=a.parentName,N=p(a,["components","mdxType","originalType","parentName"]),c=l(t),k=s,h=c["".concat(i,".").concat(k)]||c[k]||o[k]||m;return t?n.createElement(h,r(r({ref:e},N),{},{components:t})):n.createElement(h,r({ref:e},N))}));function k(a,e){var t=arguments,s=e&&e.mdxType;if("string"==typeof a||s){var m=t.length,r=new Array(m);r[0]=c;var p={};for(var i in e)hasOwnProperty.call(e,i)&&(p[i]=e[i]);p.originalType=a,p.mdxType="string"==typeof a?a:s,r[1]=p;for(var l=2;l<m;l++)r[l]=t[l];return n.createElement.apply(null,r)}return n.createElement.apply(null,t)}c.displayName="MDXCreateElement"},2054:(a,e,t)=>{t.r(e),t.d(e,{assets:()=>i,contentTitle:()=>r,default:()=>o,frontMatter:()=>m,metadata:()=>p,toc:()=>l});var n=t(3117),s=(t(7294),t(3905));const m={id:"Code - GD",title:"Gradient Descent Code",sidebar_position:1},r=void 0,p={unversionedId:"Code/Optimization/Code - GD",id:"Code/Optimization/Code - GD",title:"Gradient Descent Code",description:"All the code is written in matlab. Please visits here for a complete version of my code. The neural network code base is in reference to Dr. Chunming Wang's MATH467 project code.",source:"@site/docs/Code/Optimization/GD_code.md",sourceDirName:"Code/Optimization",slug:"/Code/Optimization/Code - GD",permalink:"/myWiki/docs/Code/Optimization/Code - GD",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/Code/Optimization/GD_code.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{id:"Code - GD",title:"Gradient Descent Code",sidebar_position:1},sidebar:"tutorialSidebar",previous:{title:"2048 Verilog",permalink:"/myWiki/docs/Code/Code - 2048"},next:{title:"Linear Programming Code",permalink:"/myWiki/docs/Code/Optimization/Code - LP"}},i={},l=[{value:"Fixed Gradient Descent Implementation",id:"fixed-gradient-descent-implementation",level:3},{value:"Result",id:"result",level:4},{value:"Analysis",id:"analysis",level:4},{value:"Steepest Gradiant Descent",id:"steepest-gradiant-descent",level:3},{value:"Result",id:"result-1",level:4},{value:"Analysis",id:"analysis-1",level:4},{value:"Conjugate Gradiant Descent",id:"conjugate-gradiant-descent",level:3},{value:"Result",id:"result-2",level:4},{value:"Analysis",id:"analysis-2",level:4},{value:"Topic of Exploration",id:"topic-of-exploration",level:3},{value:"Result",id:"result-3",level:4},{value:"Analysis",id:"analysis-3",level:4}],N={toc:l};function o(a){let{components:e,...m}=a;return(0,s.kt)("wrapper",(0,n.Z)({},N,m,{components:e,mdxType:"MDXLayout"}),(0,s.kt)("p",null,"All the code is written in matlab. Please visits ",(0,s.kt)("a",{parentName:"p",href:"https://github.com/pwang649/coding_practice/tree/main/GD"},"here")," for a complete version of my code. The neural network code base is in reference to ",(0,s.kt)("a",{parentName:"p",href:"https://dornsife.usc.edu/cf/faculty-and-staff/faculty.cfm?pid=1003805"},"Dr. Chunming Wang"),"'s MATH467 project code."),(0,s.kt)("h3",{id:"fixed-gradient-descent-implementation"},"Fixed Gradient Descent Implementation"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-{octave}"},"function fixed_GD()\n    function[mse] = meanSquaredError(y, y_pred)\n        diff = (y - y_pred).^2;\n        mse = mean(diff, \"all\");\n    end\n\nnTrials = 500;\nfixed_step_size = 0.01;\nepsilon = 1e-3; % minmal convergence error\n[xData,yData]=getData(100,2,2338580531);\n[network]=createNetwork(2,[3,3,1]);\n[Weight]=getNNWeight(network);\nWeight=randn(size(Weight));\nRMS=NaN(nTrials,1);\n[network]=setNNWeight(network,Weight);\nprev_yVal = 1;\nconvergence = -1;\nrunOnce = 1;\nfor iTrial=1:nTrials\n    [yVal,yintVal]=networkFProp(xData,network);\n    [yGrad,~]=networkBProp(network,yintVal);\n    f = NaN(1,25);\n    for i=1:size(Weight,1)\n        f(i) = -2 .* dot(squeeze(yData-yVal), squeeze(yGrad(:, i, :)));\n    end\n    Weight = Weight - fixed_step_size .* f;\n    [network]=setNNWeight(network, Weight);\n    RMS(iTrial)=meanSquaredError(yData, yVal);\n    if (all(abs(yVal - prev_yVal) < epsilon) && runOnce == 1)\n        convergence = iTrial;\n        runOnce = 0;\n    end\n    prev_yVal = yVal;\nend\ndisp(['it converges in ' num2str(convergence) ' iterations.']);\nfigure;\nplot(RMS);\nmin(RMS)\nreturn\nend\n")),(0,s.kt)("h4",{id:"result"},"Result"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"it converges in 306 iterations.\n\nans =\n\n    0.1778\n")),(0,s.kt)("p",null,(0,s.kt)("img",{src:t(9316).Z,width:"942",height:"728"})),(0,s.kt)("h4",{id:"analysis"},"Analysis"),(0,s.kt)("p",null,"In the code, I use a fixed step size of ",(0,s.kt)("span",{parentName:"p",className:"math math-inline"},(0,s.kt)("span",{parentName:"span",className:"katex"},(0,s.kt)("span",{parentName:"span",className:"katex-mathml"},(0,s.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,s.kt)("semantics",{parentName:"math"},(0,s.kt)("mrow",{parentName:"semantics"},(0,s.kt)("mn",{parentName:"mrow"},"0.01")),(0,s.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"0.01")))),(0,s.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.6444em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},"0.01"))))),", epoch of ",(0,s.kt)("span",{parentName:"p",className:"math math-inline"},(0,s.kt)("span",{parentName:"span",className:"katex"},(0,s.kt)("span",{parentName:"span",className:"katex-mathml"},(0,s.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,s.kt)("semantics",{parentName:"math"},(0,s.kt)("mrow",{parentName:"semantics"},(0,s.kt)("mn",{parentName:"mrow"},"500")),(0,s.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"500")))),(0,s.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.6444em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},"500"))))),", batch size of ",(0,s.kt)("span",{parentName:"p",className:"math math-inline"},(0,s.kt)("span",{parentName:"span",className:"katex"},(0,s.kt)("span",{parentName:"span",className:"katex-mathml"},(0,s.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,s.kt)("semantics",{parentName:"math"},(0,s.kt)("mrow",{parentName:"semantics"},(0,s.kt)("mn",{parentName:"mrow"},"100")),(0,s.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"100")))),(0,s.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.6444em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},"100"))))),", convergence error of ",(0,s.kt)("span",{parentName:"p",className:"math math-inline"},(0,s.kt)("span",{parentName:"span",className:"katex"},(0,s.kt)("span",{parentName:"span",className:"katex-mathml"},(0,s.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,s.kt)("semantics",{parentName:"math"},(0,s.kt)("mrow",{parentName:"semantics"},(0,s.kt)("mn",{parentName:"mrow"},"1"),(0,s.kt)("msup",{parentName:"mrow"},(0,s.kt)("mn",{parentName:"msup"},"0"),(0,s.kt)("mrow",{parentName:"msup"},(0,s.kt)("mo",{parentName:"mrow"},"\u2212"),(0,s.kt)("mn",{parentName:"mrow"},"3")))),(0,s.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"10^{-3}")))),(0,s.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.8141em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},"1"),(0,s.kt)("span",{parentName:"span",className:"mord"},(0,s.kt)("span",{parentName:"span",className:"mord"},"0"),(0,s.kt)("span",{parentName:"span",className:"msupsub"},(0,s.kt)("span",{parentName:"span",className:"vlist-t"},(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.8141em"}},(0,s.kt)("span",{parentName:"span",style:{top:"-3.063em",marginRight:"0.05em"}},(0,s.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,s.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mtight"},"\u2212"),(0,s.kt)("span",{parentName:"span",className:"mord mtight"},"3"))))))))))))),", and a neural network of structure ",(0,s.kt)("span",{parentName:"p",className:"math math-inline"},(0,s.kt)("span",{parentName:"span",className:"katex"},(0,s.kt)("span",{parentName:"span",className:"katex-mathml"},(0,s.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,s.kt)("semantics",{parentName:"math"},(0,s.kt)("mrow",{parentName:"semantics"},(0,s.kt)("mn",{parentName:"mrow"},"2"),(0,s.kt)("mo",{parentName:"mrow"},"\xd7"),(0,s.kt)("mn",{parentName:"mrow"},"3"),(0,s.kt)("mo",{parentName:"mrow"},"\xd7"),(0,s.kt)("mn",{parentName:"mrow"},"3"),(0,s.kt)("mo",{parentName:"mrow"},"\xd7"),(0,s.kt)("mn",{parentName:"mrow"},"1")),(0,s.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"2\\times 3\\times 3\\times 1")))),(0,s.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.7278em",verticalAlign:"-0.0833em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},"2"),(0,s.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2222em"}}),(0,s.kt)("span",{parentName:"span",className:"mbin"},"\xd7"),(0,s.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2222em"}})),(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.7278em",verticalAlign:"-0.0833em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},"3"),(0,s.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2222em"}}),(0,s.kt)("span",{parentName:"span",className:"mbin"},"\xd7"),(0,s.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2222em"}})),(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.7278em",verticalAlign:"-0.0833em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},"3"),(0,s.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2222em"}}),(0,s.kt)("span",{parentName:"span",className:"mbin"},"\xd7"),(0,s.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2222em"}})),(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.6444em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},"1"))))),"."),(0,s.kt)("p",null,"Turns out that it takes 306 iterations to converge to a root mean squared error of approximately 0.1778."),(0,s.kt)("h3",{id:"steepest-gradiant-descent"},"Steepest Gradiant Descent"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-{octave}"},"function steepest_GD()\n    function[mse] = meanSquaredError(y, y_pred)\n        diff = (y - y_pred).^2;\n        mse = mean(diff, \"all\");\n    end\n\nnTrials = 100;\nsteepest_step_size = 1; % start point for minimizing\nepsilon = 1e-5; % minmal convergence error\n[xData,yData]=getData(100,2,2338580531);\n[network]=createNetwork(2,[3,3,1]);\n[Weight]=getNNWeight(network);\nWeight=randn(size(Weight));\nRMS=NaN(nTrials,1);\n[network]=setNNWeight(network,Weight);\nprev_yVal = 1;\nconvergence = -1;\nrunOnce = 1;\nfor iTrial=1:nTrials\n    [yVal,yintVal]=networkFProp(xData,network);\n    [yGrad,~]=networkBProp(network,yintVal);\n    f = NaN(1,25);\n    for i=1:size(Weight,1)\n        f(i) = -2 .* dot(squeeze(yData-yVal), squeeze(yGrad(:, i, :)));\n    end\n    fun = @(a) meanSquaredError(yData, networkFProp(xData, setNNWeight(network, Weight - a .* f)));\n    steepest_step_size = fminsearch(fun, steepest_step_size);\n    Weight = Weight - steepest_step_size .* f;\n    [network]=setNNWeight(network, Weight);\n    RMS(iTrial)=meanSquaredError(yData, yVal);\n    if (all(abs(yVal - prev_yVal) < epsilon) && runOnce == 1)\n        convergence = iTrial;\n        runOnce = 0;\n    end\n    prev_yVal = yVal;\nend\ndisp(['it converges in ' num2str(convergence) ' iterations.']);\nfigure;\nplot(RMS);\nmin(RMS)\nreturn\nend\n")),(0,s.kt)("h4",{id:"result-1"},"Result"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"it converges in 3 iterations.\n\nans =\n\n    0.1778\n")),(0,s.kt)("p",null,(0,s.kt)("img",{src:t(6140).Z,width:"942",height:"728"})),(0,s.kt)("h4",{id:"analysis-1"},"Analysis"),(0,s.kt)("p",null,"In the code, I use a epoch of ",(0,s.kt)("span",{parentName:"p",className:"math math-inline"},(0,s.kt)("span",{parentName:"span",className:"katex"},(0,s.kt)("span",{parentName:"span",className:"katex-mathml"},(0,s.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,s.kt)("semantics",{parentName:"math"},(0,s.kt)("mrow",{parentName:"semantics"},(0,s.kt)("mn",{parentName:"mrow"},"100")),(0,s.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"100")))),(0,s.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.6444em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},"100"))))),", batch size of ",(0,s.kt)("span",{parentName:"p",className:"math math-inline"},(0,s.kt)("span",{parentName:"span",className:"katex"},(0,s.kt)("span",{parentName:"span",className:"katex-mathml"},(0,s.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,s.kt)("semantics",{parentName:"math"},(0,s.kt)("mrow",{parentName:"semantics"},(0,s.kt)("mn",{parentName:"mrow"},"100")),(0,s.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"100")))),(0,s.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.6444em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},"100"))))),", convergence error of ",(0,s.kt)("span",{parentName:"p",className:"math math-inline"},(0,s.kt)("span",{parentName:"span",className:"katex"},(0,s.kt)("span",{parentName:"span",className:"katex-mathml"},(0,s.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,s.kt)("semantics",{parentName:"math"},(0,s.kt)("mrow",{parentName:"semantics"},(0,s.kt)("mn",{parentName:"mrow"},"1"),(0,s.kt)("msup",{parentName:"mrow"},(0,s.kt)("mn",{parentName:"msup"},"0"),(0,s.kt)("mrow",{parentName:"msup"},(0,s.kt)("mo",{parentName:"mrow"},"\u2212"),(0,s.kt)("mn",{parentName:"mrow"},"5")))),(0,s.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"10^{-5}")))),(0,s.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.8141em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},"1"),(0,s.kt)("span",{parentName:"span",className:"mord"},(0,s.kt)("span",{parentName:"span",className:"mord"},"0"),(0,s.kt)("span",{parentName:"span",className:"msupsub"},(0,s.kt)("span",{parentName:"span",className:"vlist-t"},(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.8141em"}},(0,s.kt)("span",{parentName:"span",style:{top:"-3.063em",marginRight:"0.05em"}},(0,s.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,s.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mtight"},"\u2212"),(0,s.kt)("span",{parentName:"span",className:"mord mtight"},"5"))))))))))))),", and a neural network of structure ",(0,s.kt)("span",{parentName:"p",className:"math math-inline"},(0,s.kt)("span",{parentName:"span",className:"katex"},(0,s.kt)("span",{parentName:"span",className:"katex-mathml"},(0,s.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,s.kt)("semantics",{parentName:"math"},(0,s.kt)("mrow",{parentName:"semantics"},(0,s.kt)("mn",{parentName:"mrow"},"2"),(0,s.kt)("mo",{parentName:"mrow"},"\xd7"),(0,s.kt)("mn",{parentName:"mrow"},"3"),(0,s.kt)("mo",{parentName:"mrow"},"\xd7"),(0,s.kt)("mn",{parentName:"mrow"},"3"),(0,s.kt)("mo",{parentName:"mrow"},"\xd7"),(0,s.kt)("mn",{parentName:"mrow"},"1")),(0,s.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"2\\times 3\\times 3\\times 1")))),(0,s.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.7278em",verticalAlign:"-0.0833em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},"2"),(0,s.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2222em"}}),(0,s.kt)("span",{parentName:"span",className:"mbin"},"\xd7"),(0,s.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2222em"}})),(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.7278em",verticalAlign:"-0.0833em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},"3"),(0,s.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2222em"}}),(0,s.kt)("span",{parentName:"span",className:"mbin"},"\xd7"),(0,s.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2222em"}})),(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.7278em",verticalAlign:"-0.0833em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},"3"),(0,s.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2222em"}}),(0,s.kt)("span",{parentName:"span",className:"mbin"},"\xd7"),(0,s.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2222em"}})),(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.6444em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},"1"))))),"."),(0,s.kt)("p",null,"Turns out that it takes 3 iterations to converge to a root mean squared error of approximately 0.1778. As we can see here, the steepest gradiant method converges much faster than the fixed step size gradiant method."),(0,s.kt)("h3",{id:"conjugate-gradiant-descent"},"Conjugate Gradiant Descent"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-{octave}"},"function conjugate_GD()\n    function[mse] = meanSquaredError(y, y_pred)\n        diff = (y - y_pred).^2;\n        mse = mean(diff, \"all\");\n    end\nnTrials = 100;\nconjugate_step_size = 1; % start point for minimizing\nepsilon = 1e-5; % minmal convergence error\n[xData,yData]=getData(100,2,2338580531);\n[network]=createNetwork(2,[3,3,1]);\n[Weight]=getNNWeight(network);\nWeight=randn(size(Weight));\nRMS=NaN(nTrials,1);\n[network]=setNNWeight(network,Weight);\nprev_yVal = 1;\nconvergence = -1;\nrunOnce = 1;\n[yVal,yintVal]=networkFProp(xData,network);\n[yGrad,~]=networkBProp(network,yintVal);\ng = NaN(1,25);\nfor i=1:size(Weight,1)\n    g(i) = -2 .* dot(squeeze(yData-yVal), squeeze(yGrad(:, i, :)));\nend\nd = -1 .* g;\nRMS(1)=meanSquaredError(yData, yVal);\nfor iTrial=2:nTrials\n    fun = @(a) meanSquaredError(yData, networkFProp(xData, setNNWeight(network, Weight + a .* d)));\n    conjugate_step_size = fminsearch(fun, conjugate_step_size);\n    % update weight\n    Weight = Weight + conjugate_step_size .* d;\n    [network]=setNNWeight(network, Weight);\n    % evaluate gradient for the next iteration\n    [yVal,yintVal]=networkFProp(xData,network);\n    [yGrad,~]=networkBProp(network,yintVal);\n    next_g = NaN(1, 25);\n    for i=1:size(Weight,1)\n        next_g(i) = -2 .* dot(squeeze(yData-yVal), squeeze(yGrad(:, i, :)));\n    end\n    % calculate beta using the Fletcher\u2013Reeves method\n    beta = dot(transpose(next_g), next_g) ./ dot(transpose(g), g);\n    d = -1 .* next_g + beta .* d;\n    RMS(iTrial)=meanSquaredError(yData, yVal);\n    g = next_g;\n    if (all(abs(yVal - prev_yVal) < epsilon) && runOnce == 1)\n        convergence = iTrial;\n        runOnce = 0;\n    end\n    prev_yVal = yVal;\nend\ndisp(['it converges in ' num2str(convergence) ' iterations.']);\nfigure;\nplot(RMS);\nmin(RMS)\nreturn\nend\n")),(0,s.kt)("h4",{id:"result-2"},"Result"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"it converges in 3 iterations.\n\nans =\n\n    0.1778\n")),(0,s.kt)("p",null,(0,s.kt)("img",{src:t(2813).Z,width:"942",height:"728"})),(0,s.kt)("h4",{id:"analysis-2"},"Analysis"),(0,s.kt)("p",null,"In the code, I use a epoch of ",(0,s.kt)("span",{parentName:"p",className:"math math-inline"},(0,s.kt)("span",{parentName:"span",className:"katex"},(0,s.kt)("span",{parentName:"span",className:"katex-mathml"},(0,s.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,s.kt)("semantics",{parentName:"math"},(0,s.kt)("mrow",{parentName:"semantics"},(0,s.kt)("mn",{parentName:"mrow"},"100")),(0,s.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"100")))),(0,s.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.6444em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},"100"))))),", batch size of ",(0,s.kt)("span",{parentName:"p",className:"math math-inline"},(0,s.kt)("span",{parentName:"span",className:"katex"},(0,s.kt)("span",{parentName:"span",className:"katex-mathml"},(0,s.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,s.kt)("semantics",{parentName:"math"},(0,s.kt)("mrow",{parentName:"semantics"},(0,s.kt)("mn",{parentName:"mrow"},"100")),(0,s.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"100")))),(0,s.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.6444em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},"100"))))),", convergence error of ",(0,s.kt)("span",{parentName:"p",className:"math math-inline"},(0,s.kt)("span",{parentName:"span",className:"katex"},(0,s.kt)("span",{parentName:"span",className:"katex-mathml"},(0,s.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,s.kt)("semantics",{parentName:"math"},(0,s.kt)("mrow",{parentName:"semantics"},(0,s.kt)("mn",{parentName:"mrow"},"1"),(0,s.kt)("msup",{parentName:"mrow"},(0,s.kt)("mn",{parentName:"msup"},"0"),(0,s.kt)("mrow",{parentName:"msup"},(0,s.kt)("mo",{parentName:"mrow"},"\u2212"),(0,s.kt)("mn",{parentName:"mrow"},"5")))),(0,s.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"10^{-5}")))),(0,s.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.8141em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},"1"),(0,s.kt)("span",{parentName:"span",className:"mord"},(0,s.kt)("span",{parentName:"span",className:"mord"},"0"),(0,s.kt)("span",{parentName:"span",className:"msupsub"},(0,s.kt)("span",{parentName:"span",className:"vlist-t"},(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.8141em"}},(0,s.kt)("span",{parentName:"span",style:{top:"-3.063em",marginRight:"0.05em"}},(0,s.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,s.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mtight"},"\u2212"),(0,s.kt)("span",{parentName:"span",className:"mord mtight"},"5"))))))))))))),", and a neural network of structure ",(0,s.kt)("span",{parentName:"p",className:"math math-inline"},(0,s.kt)("span",{parentName:"span",className:"katex"},(0,s.kt)("span",{parentName:"span",className:"katex-mathml"},(0,s.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,s.kt)("semantics",{parentName:"math"},(0,s.kt)("mrow",{parentName:"semantics"},(0,s.kt)("mn",{parentName:"mrow"},"2"),(0,s.kt)("mo",{parentName:"mrow"},"\xd7"),(0,s.kt)("mn",{parentName:"mrow"},"3"),(0,s.kt)("mo",{parentName:"mrow"},"\xd7"),(0,s.kt)("mn",{parentName:"mrow"},"3"),(0,s.kt)("mo",{parentName:"mrow"},"\xd7"),(0,s.kt)("mn",{parentName:"mrow"},"1")),(0,s.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"2\\times 3\\times 3\\times 1")))),(0,s.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.7278em",verticalAlign:"-0.0833em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},"2"),(0,s.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2222em"}}),(0,s.kt)("span",{parentName:"span",className:"mbin"},"\xd7"),(0,s.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2222em"}})),(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.7278em",verticalAlign:"-0.0833em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},"3"),(0,s.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2222em"}}),(0,s.kt)("span",{parentName:"span",className:"mbin"},"\xd7"),(0,s.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2222em"}})),(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.7278em",verticalAlign:"-0.0833em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},"3"),(0,s.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2222em"}}),(0,s.kt)("span",{parentName:"span",className:"mbin"},"\xd7"),(0,s.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2222em"}})),(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.6444em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},"1"))))),"."),(0,s.kt)("p",null,"Turns out that it takes 3 iterations to converge to a root mean squared error of approximately 0.1778. As we can see here, the conjugate gradiant method performs about the same as does the steepest descent method."),(0,s.kt)("h3",{id:"topic-of-exploration"},"Topic of Exploration"),(0,s.kt)("p",null,"I will choose to explore the topic of:"),(0,s.kt)("p",null,(0,s.kt)("em",{parentName:"p"},"Convergence of the algorithm for different selection of step-sizes for fixed step-size"),"\nmethod."),(0,s.kt)("h4",{id:"result-3"},"Result"),(0,s.kt)("p",null,"I will choose four different fix step sizes to explore: ",(0,s.kt)("span",{parentName:"p",className:"math math-inline"},(0,s.kt)("span",{parentName:"span",className:"katex"},(0,s.kt)("span",{parentName:"span",className:"katex-mathml"},(0,s.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,s.kt)("semantics",{parentName:"math"},(0,s.kt)("mrow",{parentName:"semantics"},(0,s.kt)("mn",{parentName:"mrow"},"1"),(0,s.kt)("mo",{parentName:"mrow",separator:"true"},","),(0,s.kt)("mtext",{parentName:"mrow"},"\u2005"),(0,s.kt)("mn",{parentName:"mrow"},"0.1"),(0,s.kt)("mo",{parentName:"mrow",separator:"true"},","),(0,s.kt)("mtext",{parentName:"mrow"},"\u2005"),(0,s.kt)("mn",{parentName:"mrow"},"0.01"),(0,s.kt)("mo",{parentName:"mrow",separator:"true"},","),(0,s.kt)("mtext",{parentName:"mrow"},"\u2005"),(0,s.kt)("mn",{parentName:"mrow"},"0.001")),(0,s.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"1,\\: 0.1,\\: 0.01,\\: 0.001")))),(0,s.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.8389em",verticalAlign:"-0.1944em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},"1"),(0,s.kt)("span",{parentName:"span",className:"mpunct"},","),(0,s.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2222em"}}),(0,s.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.1667em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},"0.1"),(0,s.kt)("span",{parentName:"span",className:"mpunct"},","),(0,s.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2222em"}}),(0,s.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.1667em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},"0.01"),(0,s.kt)("span",{parentName:"span",className:"mpunct"},","),(0,s.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2222em"}}),(0,s.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.1667em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},"0.001")))))," with an epoch of ",(0,s.kt)("span",{parentName:"p",className:"math math-inline"},(0,s.kt)("span",{parentName:"span",className:"katex"},(0,s.kt)("span",{parentName:"span",className:"katex-mathml"},(0,s.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,s.kt)("semantics",{parentName:"math"},(0,s.kt)("mrow",{parentName:"semantics"},(0,s.kt)("mn",{parentName:"mrow"},"5000")),(0,s.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"5000")))),(0,s.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.6444em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},"5000"))))),". ",(0,s.kt)("span",{parentName:"p",className:"math math-inline"},(0,s.kt)("span",{parentName:"span",className:"katex"},(0,s.kt)("span",{parentName:"span",className:"katex-mathml"},(0,s.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,s.kt)("semantics",{parentName:"math"},(0,s.kt)("mrow",{parentName:"semantics"},(0,s.kt)("mi",{parentName:"mrow"},"\u03f5")),(0,s.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"\\epsilon")))),(0,s.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.4306em"}}),(0,s.kt)("span",{parentName:"span",className:"mord mathnormal"},"\u03f5")))))," means the minimum error between trials for the algorithm to be considered converged."),(0,s.kt)("table",null,(0,s.kt)("thead",{parentName:"table"},(0,s.kt)("tr",{parentName:"thead"},(0,s.kt)("th",{parentName:"tr",align:"center"},"Step Size"),(0,s.kt)("th",{parentName:"tr",align:"center"},(0,s.kt)("span",{parentName:"th",className:"math math-inline"},(0,s.kt)("span",{parentName:"span",className:"katex"},(0,s.kt)("span",{parentName:"span",className:"katex-mathml"},(0,s.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,s.kt)("semantics",{parentName:"math"},(0,s.kt)("mrow",{parentName:"semantics"},(0,s.kt)("mi",{parentName:"mrow"},"\u03f5")),(0,s.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"\\epsilon")))),(0,s.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.4306em"}}),(0,s.kt)("span",{parentName:"span",className:"mord mathnormal"},"\u03f5")))))),(0,s.kt)("th",{parentName:"tr",align:"center"},"Trials to Converge"))),(0,s.kt)("tbody",{parentName:"table"},(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"center"},"1"),(0,s.kt)("td",{parentName:"tr",align:"center"},"0.0001"),(0,s.kt)("td",{parentName:"tr",align:"center"},"129")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"center"},"0.1"),(0,s.kt)("td",{parentName:"tr",align:"center"},"0.0001"),(0,s.kt)("td",{parentName:"tr",align:"center"},"268")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"center"},"0.01"),(0,s.kt)("td",{parentName:"tr",align:"center"},"0.0001"),(0,s.kt)("td",{parentName:"tr",align:"center"},"702")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:"center"},"0.001"),(0,s.kt)("td",{parentName:"tr",align:"center"},"0.0001"),(0,s.kt)("td",{parentName:"tr",align:"center"},"3042")))),(0,s.kt)("h4",{id:"analysis-3"},"Analysis"),(0,s.kt)("p",null,"We can see here, as we decrease the step size by ",(0,s.kt)("span",{parentName:"p",className:"math math-inline"},(0,s.kt)("span",{parentName:"span",className:"katex"},(0,s.kt)("span",{parentName:"span",className:"katex-mathml"},(0,s.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,s.kt)("semantics",{parentName:"math"},(0,s.kt)("mrow",{parentName:"semantics"},(0,s.kt)("mn",{parentName:"mrow"},"10")),(0,s.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"10")))),(0,s.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.6444em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},"10"))))),", trials to converge increase by approximately ",(0,s.kt)("span",{parentName:"p",className:"math math-inline"},(0,s.kt)("span",{parentName:"span",className:"katex"},(0,s.kt)("span",{parentName:"span",className:"katex-mathml"},(0,s.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,s.kt)("semantics",{parentName:"math"},(0,s.kt)("mrow",{parentName:"semantics"},(0,s.kt)("mn",{parentName:"mrow"},"2")),(0,s.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"2")))),(0,s.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.6444em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},"2"))))),". It makes sense that when we take smaller steps, the iteration it takes to reach the goal will be greater."))}o.isMDXComponent=!0},2813:(a,e,t)=>{t.d(e,{Z:()=>n});const n=t.p+"assets/images/conjugate_GD-db73f17d123bc087a0464eb964725891.png"},9316:(a,e,t)=>{t.d(e,{Z:()=>n});const n=t.p+"assets/images/fixed_GD-c0bcc41ad0dbbe89df5b05628c362544.png"},6140:(a,e,t)=>{t.d(e,{Z:()=>n});const n=t.p+"assets/images/steepest_GD-64a9c8131e48ab6c64c56ad296fafb38.png"}}]);