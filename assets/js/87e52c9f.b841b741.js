"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[5822],{3905:(e,t,i)=>{i.d(t,{Zo:()=>_,kt:()=>g});var n=i(67294);function a(e,t,i){return t in e?Object.defineProperty(e,t,{value:i,enumerable:!0,configurable:!0,writable:!0}):e[t]=i,e}function r(e,t){var i=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),i.push.apply(i,n)}return i}function o(e){for(var t=1;t<arguments.length;t++){var i=null!=arguments[t]?arguments[t]:{};t%2?r(Object(i),!0).forEach((function(t){a(e,t,i[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(i)):r(Object(i)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(i,t))}))}return e}function l(e,t){if(null==e)return{};var i,n,a=function(e,t){if(null==e)return{};var i,n,a={},r=Object.keys(e);for(n=0;n<r.length;n++)i=r[n],t.indexOf(i)>=0||(a[i]=e[i]);return a}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(n=0;n<r.length;n++)i=r[n],t.indexOf(i)>=0||Object.prototype.propertyIsEnumerable.call(e,i)&&(a[i]=e[i])}return a}var s=n.createContext({}),p=function(e){var t=n.useContext(s),i=t;return e&&(i="function"==typeof e?e(t):o(o({},t),e)),i},_=function(e){var t=p(e.components);return n.createElement(s.Provider,{value:t},e.children)},m="mdxType",c={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},d=n.forwardRef((function(e,t){var i=e.components,a=e.mdxType,r=e.originalType,s=e.parentName,_=l(e,["components","mdxType","originalType","parentName"]),m=p(i),d=a,g=m["".concat(s,".").concat(d)]||m[d]||c[d]||r;return i?n.createElement(g,o(o({ref:t},_),{},{components:i})):n.createElement(g,o({ref:t},_))}));function g(e,t){var i=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var r=i.length,o=new Array(r);o[0]=d;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l[m]="string"==typeof e?e:a,o[1]=l;for(var p=2;p<r;p++)o[p]=i[p];return n.createElement.apply(null,o)}return n.createElement.apply(null,i)}d.displayName="MDXCreateElement"},54075:(e,t,i)=>{i.r(t),i.d(t,{assets:()=>s,contentTitle:()=>o,default:()=>c,frontMatter:()=>r,metadata:()=>l,toc:()=>p});var n=i(87462),a=(i(67294),i(3905));const r={id:"Research - Placement Optimization",title:"Placement Optimization",sidebar_position:1},o=void 0,l={unversionedId:"Research/Research - Placement Optimization",id:"Research/Research - Placement Optimization",title:"Placement Optimization",description:"Introduction",source:"@site/docs/Research/Placement_Op.md",sourceDirName:"Research",slug:"/Research/Research - Placement Optimization",permalink:"/myWiki/Research/Research - Placement Optimization",draft:!1,editUrl:"https://github.com/pwang649/myWiki/edit/main/docs/Research/Placement_Op.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{id:"Research - Placement Optimization",title:"Placement Optimization",sidebar_position:1},sidebar:"tutorialSidebar",previous:{title:"MPC Demo",permalink:"/myWiki/Code/Robotics/Code - Robotics - MPC"},next:{title:"Four Models",permalink:"/myWiki/Survival Analysis/Survival Analysis - Four Models"}},s={},p=[{value:"Introduction",id:"introduction",level:3},{value:"Problem",id:"problem",level:3},{value:"Methods",id:"methods",level:3},{value:"I. Image-based approach algorithm",id:"i-image-based-approach-algorithm",level:4},{value:"II. Pybullet-based repetitive checking (rotation-based)",id:"ii-pybullet-based-repetitive-checking-rotation-based",level:4},{value:"III. Pybullet-based repetitive checking (rotation-and-position-based)",id:"iii-pybullet-based-repetitive-checking-rotation-and-position-based",level:4},{value:"Results",id:"results",level:3},{value:"I. First method",id:"i-first-method",level:4},{value:"II. Second method",id:"ii-second-method",level:4},{value:"III. Third method",id:"iii-third-method",level:4}],_={toc:p},m="wrapper";function c(e){let{components:t,...i}=e;return(0,a.kt)(m,(0,n.Z)({},_,i,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h3",{id:"introduction"},"Introduction"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"The current method used to find a desirable placement for an object is to use an approach similar to the CNN with 16 different rotational degrees and 160 x 89 discretization of the workspace.")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"Using this method, the results show significant improvement over those using the method of uniform sampling."),(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",{parentName:"pre"},"Using template-based sampling, we have 1228 valid samples from 2840 tires.\nUsing template-based sampling, we have 113 valid probs from 142 probs\nUsing template-based sampling, type failures: 1: 466 2: 0 3: 734 4: 815 5: 139 6: 12\nUsing uniform sampling, we have 104 valid samples from 2840 tires.\nUsing uniform sampling, we have 41 valid probs from 142 probs\nUsing uniform sampling, type failures: 1: 2314 2: 0 3: 1435 4: 1793 5: 1091 6: 629\n")))),(0,a.kt)("h3",{id:"problem"},"Problem"),(0,a.kt)("p",null,"However, observing the results, we can see failure reason 1 (collision with fixed and movable obstacles) is around 600 / 2840 samples and failure reason 5 (collision with future moved objects) is around 200 / 2840 samples. These failures can be solved using a filter with better precision so that we can get even better results."),(0,a.kt)("h3",{id:"methods"},"Methods"),(0,a.kt)("h4",{id:"i-image-based-approach-algorithm"},"I. Image-based approach algorithm"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"Check whether the placement returned from the first stage CNN method is collision-free with fixed, movable, and future obstacles."),(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",{parentName:"pre",className:"language-python"},"# in evaluate_template_based_sampling_new.py\nif any(pairwise_collision(obj_pid2obj[place_movable].pid, obst.pid) for obst in\n                obstacle_objects + fixed_obstacles) or if_collides_fut_moved_objects(fut_vols,\n                                                                                        obj_pid2obj[place_movable]):\n"))),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"If the above condition is true, the function ",(0,a.kt)("inlineCode",{parentName:"p"},"optimize_placement_pose()")," is called to get a finer placement using the current placement info.")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"In ",(0,a.kt)("inlineCode",{parentName:"p"},"optimize_placement_pose()")," function, it first generates a scaled-up image representation of the workspace and adds a white padding surrounding the workspace."),(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",{parentName:"pre",className:"language-python"},"# In template_based_sampling_new.py\nimg = create_initial_img(obj_pose_pairs, finer_steps)\n\nx_in_img_without_rot, y_in_img_without_rot, rot, x_in_sim, y_in_sim, pitch, x_in_img_with_rot, y_in_img_with_rot, rot_degree_in_img = curr_placement\n\nmargin = to_place_obj_h_in_img * 0.5\nimg = np.pad(img, math.ceil(margin * finer_steps), constant_values=1)\n"))),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"Then, the image will be clipped into a smaller image surrounding the proposed object placement with a window size twice as big as the object."),(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",{parentName:"pre",className:"language-python"},"up_clip = int((y_in_img_without_rot - top_pad_size_rot0 + margin - to_place_obj_h_in_img/2 - margin) * finer_steps)\ndown_clip = int(up_clip + to_place_obj_h_in_img * finer_steps + 2 * margin * finer_steps)\nleft_clip = int((x_in_img_without_rot - left_pad_size_rot0 + margin - to_place_obj_w_in_img/2 - margin) * finer_steps)\nright_clip = int(left_clip + to_place_obj_h_in_img * finer_steps + 2 * margin * finer_steps)\nclipped_img = img[up_clip:down_clip, left_clip:right_clip]\n"))),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"Create images with various rotations of the to-place object given the number of angles and original rotation."),(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",{parentName:"pre",className:"language-python"},"# Return a list of degree differences given the parent and child number of angles\ndegree_diff_lst = get_finer_degrees_diff_list(num_angles, finer_num_angles)\nrotated_imgs = np.zeros((finer_num_angles, clipped_img.shape[0], clipped_img.shape[1]))\n\n# Draw bowl with different degrees\nfor index, rot_degree in enumerate(degree_diff_lst):\n    x_center = clipped_img.shape[1] / 2\n    y_center = clipped_img.shape[0] / 2\n\n    # compute 4 corner points, assuming the obj has no rotation\n    x1_in_img = x_center - finer_steps * to_place_obj_w_in_img / 2 - finer_steps / 10 # pixel coordinates\n    y1_in_img = y_center - finer_steps * to_place_obj_h_in_img / 2 - finer_steps / 10\n\n    x2_in_img = x1_in_img + to_place_obj_w_in_img * finer_steps + finer_steps / 10\n    y2_in_img = y1_in_img\n\n    x3_in_img = x2_in_img\n    y3_in_img = y1_in_img + to_place_obj_h_in_img * finer_steps + finer_steps / 10\n\n    x4_in_img = x1_in_img\n    y4_in_img = y3_in_img\n\n    # rotate the corner points around the center of the object\n    x1p, y1p = rotate_on_2d(x1_in_img, y1_in_img, x_center, y_center, rot_degree + rot)\n    x2p, y2p = rotate_on_2d(x2_in_img, y2_in_img, x_center, y_center, rot_degree + rot)\n    x3p, y3p = rotate_on_2d(x3_in_img, y3_in_img, x_center, y_center, rot_degree + rot)\n    x4p, y4p = rotate_on_2d(x4_in_img, y4_in_img, x_center, y_center, rot_degree + rot)\n\n    r = np.array([y1p, y2p, y3p, y4p])\n    c = np.array([x1p, x2p, x3p, x4p])\n\n    rr, cc = draw.polygon(r, c, shape=img.shape)\n    rotated_imgs[index][rr, cc] = 1\n"))),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"Multiply the original clipped image with each rotated image and sum each cell of the resulting matrix."),(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",{parentName:"pre",className:"language-python"},"# Multiply each with the original image\nrotated_imgs_tensor = torch.from_numpy(rotated_imgs).float().to(device)\nclipped_img_tensor = torch.from_numpy(clipped_img).float().to(device)\nvalues = []\nfor i in range(finer_num_angles):\n    values.append(torch.multiply(clipped_img_tensor, rotated_imgs_tensor[i]).sum())\n"))),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"Return the best rotation (smallest value). If there exist multiple smallest values, we pick one randomly."),(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",{parentName:"pre",className:"language-python"},"smallest = min(values)\nrand_choices = []\nfor i, v in enumerate(values):\n    if v == smallest:\n        rand_choices.append(i)\nrot_id = random.choice(rand_choices)\nnew_rot = rot_degree_in_img + degree_diff_lst[rot_id]\nrot_degree_in_sim = - new_rot / 180 * np.pi\n\nreturn x_in_img_without_rot, y_in_img_without_rot, new_rot, x_in_sim, y_in_sim, rot_degree_in_sim, x_in_img_with_rot, y_in_img_with_rot, new_rot\n"))),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"Finally, we update the position using the new returned placement."))),(0,a.kt)("h4",{id:"ii-pybullet-based-repetitive-checking-rotation-based"},"II. Pybullet-based repetitive checking (rotation-based)"),(0,a.kt)("p",null,"Following step 1 in the previous method, this method rotates the object little by little in the Pybullet simulation until there exists a collision-free degree or every degree has been tried."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"for i in get_finer_degrees_diff_list(num_angles, 20):\n    subsample_cont_placement_pose = recover_placement_pose((x_in_img_without_rot, y_in_img_without_rot,\n                                                            rot, x, y, - (rot + i) / 180 * np.pi,\n                                                            x_in_img_with_rot, y_in_img_with_rot,\n                                                            rot_degree_in_img),\n                                                            tamp_prob, place_movable, target_container)\n    set_pose(place_movable, subsample_cont_placement_pose)\n    if not (any(pairwise_collision(obj_pid2obj[place_movable].pid, obst.pid) for obst in\n                obstacle_objects + fixed_obstacles) or if_collides_fut_moved_objects(fut_vols,\n                                                                                        obj_pid2obj[\n                                                                                            place_movable])):\n        break\n")),(0,a.kt)("h4",{id:"iii-pybullet-based-repetitive-checking-rotation-and-position-based"},"III. Pybullet-based repetitive checking (rotation-and-position-based)"),(0,a.kt)("p",null,"Similar to method 2, this method not only checks for various rotations, but it also tries fine adjustments in position."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"h_interval = stride_h / scale\nw_interval = stride_w / scale\nx_lower = x - w_interval / 2\ny_lower = y - h_interval / 2\nsmaller_w_step_size = w_interval / 5\nsmaller_h_step_size = h_interval / 5\nfor i in get_finer_degrees_diff_list(num_angles, 20):\n    for dx in [x_lower + (j * smaller_w_step_size) for j in range(0, 5)]:\n        for dy in [y_lower + (k * smaller_h_step_size) for k in range(0, 5)]:\n            subsample_cont_placement_pose = recover_placement_pose((x_in_img_without_rot, y_in_img_without_rot, rot, dx, dy, - (rot + i) / 180 * np.pi, x_in_img_with_rot, y_in_img_with_rot, rot_degree_in_img),\n                                                                    tamp_prob, place_movable, target_container)\n            set_pose(place_movable, subsample_cont_placement_pose)\n            if not (any(pairwise_collision(obj_pid2obj[place_movable].pid, obst.pid) for obst in obstacle_objects + fixed_obstacles) or if_collides_fut_moved_objects(fut_vols, obj_pid2obj[place_movable])):\n                break\n        else:\n            continue\n        break\n    else:\n        continue\n    break\n")),(0,a.kt)("h3",{id:"results"},"Results"),(0,a.kt)("h4",{id:"i-first-method"},"I. First method"),(0,a.kt)("p",null,"Using 20 sub-angles and enlarging by a factor of 8."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"Using template-based sampling, we have 1373 valid samples from 2840 tires.\nUsing template-based sampling, we have 125 valid probs from 142 probs\nUsing template-based sampling, type failures: 1: 283 2: 0 3: 688 4: 837 5: 76 6: 15\n")),(0,a.kt)("h4",{id:"ii-second-method"},"II. Second method"),(0,a.kt)("p",null,"Similar result using 20 sub-angles."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"Using template-based sampling, we have 1361 valid samples from 2840 tires.\nUsing template-based sampling, we have 125 valid probs from 142 probs\nUsing template-based sampling, type failures: 1: 250 2: 0 3: 684 4: 858 5: 96 6: 23\n")),(0,a.kt)("h4",{id:"iii-third-method"},"III. Third method"),(0,a.kt)("p",null,"Using 20 sub-angles and a 5x5 sub-stride size, we have a few more valid samples and fewer failure reasons 1 and 5."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"Using template-based sampling, we have 1493 valid samples from 2840 tires.\nUsing template-based sampling, we have 125 valid probs from 142 probs\nUsing template-based sampling, type failures: 1: 149 2: 0 3: 659 4: 814 5: 43 6: 40\n")))}c.isMDXComponent=!0}}]);